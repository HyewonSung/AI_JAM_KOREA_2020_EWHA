{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Fast text를 이용한 유사도 계산>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 필요한 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "ko_model = models.fasttext.load_facebook_model('cc.ko.300.bin.gz')\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 새로운 글 & 기존 글(상위 5개) 토큰 사이 유사도 검사 \n",
    "### 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('petition_final.xlsx')[['제목', '청원수', '본문']]\n",
    "okt = Okt()\n",
    "\n",
    "delete_word = ['현재', '지금', '상반기', '하반기', '이', '그', '그녀', '저', '것', '들', '제', '저희', '너', '되', '물', '수', '않', '없', '아니',\n",
    "               '때문', '곳', '등', '들', '중', '좀', '잘', '더', '더욱', '경우', '후', '때', '있', '하', '생각', '청원', '국민청원']\n",
    "\n",
    "final_token = []\n",
    "new_final_token = []\n",
    "df = pd.DataFrame(columns=['청원글', '청원수', '상위토큰', '유사도'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 인풋 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로 청원할 글을 입력하세요: 코로나19 확진자가 전날보다 34명 증가했다고 합니다. 코로나 방지를 위해 외국인 입국 금지시켜주세요.  이처럼 최근 다시 코로나 확진자가 늘어나고 있는 상황입니다. 해외 유입 외국인을 계속 받으니까 지역사회 감염자가 늘어나는 것 아닙니까? 수개월 동안의 의료진과 국민들의 노력과 시간이 모두 수포로 돌아가는 것 같아 짜증나네요. 우리나라 국적인 사람들은 어쩔 수 없다고 해도, 해외 국적인 외국인들까지 계속 입국을 허용하는 것은 이와 같은 코로나 사태 해결에 도움이 안된다고 생각합니다. 외국인 입국 금지 강력히 원합니다. \n"
     ]
    }
   ],
   "source": [
    "# 인풋\n",
    "new_petition = okt.nouns(input(\"새로 청원할 글을 입력하세요: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 새로운 청원글 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['코로나', '외국인', '입국', '것', '확', '진자', '금지', '해외', '계속', '국적', '전날', '명', '증가', '방지', '위해']\n"
     ]
    }
   ],
   "source": [
    "# 새로운 청원글 토큰화\n",
    "new_text = nltk.Text(new_petition)\n",
    "new_selected_words = [f[0] for f in new_text.vocab().most_common(15)]\n",
    "print(new_selected_words)\n",
    "\n",
    "# 새로운 청원글 불용어 제거\n",
    "for word in new_selected_words:\n",
    "    if word not in delete_word:\n",
    "        new_final_token.append(word)\n",
    "        \n",
    "new_final_token = new_final_token[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['코로나', '외국인', '입국', '확', '진자']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_final_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 기존 청원글 토큰화\n",
    "### 5. 제목이랑 본문상위토큰 합치기\n",
    "### 6. 불용어 제거하기 -> 5개 최종 토큰만 추출하여 final_token에 저장\n",
    "### 7. 새로운 글 & 기존의 청원글과 자카드 유사도 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3. 기존 청원글 토큰화\n",
    "\n",
    "# for i in range(10):\n",
    "for i in range(data['제목'].count()):\n",
    "    # 제목 토큰\n",
    "    title_token = okt.nouns(data['제목'][i])\n",
    "    # 콘텐트 토큰\n",
    "    content_token = okt.nouns(data['본문'][i])\n",
    "    text = nltk.Text(content_token)\n",
    "    # 출현 빈도가 높은 본문 상위 토큰 15개\n",
    "    selected_words = [f[0] for f in text.vocab().most_common(15)]\n",
    "    \n",
    "# 4. 제목이랑 본문상위토큰 15개 합치기\n",
    "    hap_token = title_token + selected_words\n",
    "#     print(\"제목 토큰 & 본문에서 가장 많이 나온 명사 15개: \\n\", hap_token)\n",
    "    \n",
    "# 5. 불용어 제거하기\n",
    "    for word in hap_token:\n",
    "        if word not in delete_word:\n",
    "            final_token.append(word)\n",
    "            \n",
    "# 5-2. 불용어 제거한 후, 5개 토큰만 추출\n",
    "    final_token = final_token[:5]\n",
    "#     print(\"불용어 제거한 최종 토큰: \\n\", final_token)\n",
    "    \n",
    "\n",
    "#     print(\"-\" * 50)\n",
    "    \n",
    "# 6. 새로운 글 & 기존의 청원글과 자카드 유사도 검사\n",
    "    def Jaccard_similarity(existing, new):\n",
    "        # 중복되는 단어 제거\n",
    "        existing = set(existing)\n",
    "        new = set(new)\n",
    "        return len(existing & new) / len(existing | new)\n",
    "\n",
    "    # 기존의 모든 청원글과 새로운 청원글의 자카드 유사도 출력\n",
    "#     print('\"' + data['제목'][i] + '\"' + \" 청원글과의 유사도: \", Jaccard_similarity(final_token, new_final_token))\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "    df = df.append({'청원글':data['제목'][i], '청원수': data['청원수'][i], '상위토큰': final_token, '유사도':Jaccard_similarity(final_token, new_final_token)}, ignore_index=True)\n",
    "    final_token = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. sorting된 순서로 자카드 유사도 가장 높은 상위 5개 글 제시 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by = ['유사도'], axis = 0, ascending=False, inplace=False)  # 유사도 기준 내림차순으로 정렬\n",
    "sorted_petition = sorted_df.iloc[:5]  # 상위 5개 글 추출 \n",
    "\n",
    "# 자카드 유사도가 가장 높은 상위 5개 청원글 출력\n",
    "print(\"자카드 유사도가 가장 높은 상위 5개 청원글: \\n\", sorted_petition)  # 제목과 청원수, 상위토큰, 유사도 나옴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 유사도 그래프 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "# 그래프\n",
    "for i in range(5):\n",
    "    words += sorted_petition.iloc[i].iloc[2] + new_final_token # 기존 글 다섯개 토큰 + 새로운 글 다섯개 토큰\n",
    "    \n",
    "pca = PCA(n_components=2)\n",
    "xys = pca.fit_transform([ko_model.wv.word_vec(w) for w in words])\n",
    "xs = xys[:,0]\n",
    "ys = xys[:,1]\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus'] = False # 마이너스 부호 깨짐 방지\n",
    "plt.rc('font', family = 'NanumGothic')   #나눔고딕을 기본 글꼴로 설정\n",
    "plt.figure(figsize=(14, 10), )\n",
    "plt.scatter(xs, ys, marker='o')\n",
    "for i, v in enumerate(words):\n",
    "    plt.annotate(v, xy=(xs[i], ys[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 새로운 청원글 & 기존 청원글 상위토큰(단어) 1:1 유사도 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 새로운 청원글의 상위토큰: new_final_token\n",
    "# 기존 청원글 5개의 상위 토큰: sorted_petition['상위토큰']\n",
    "prediction = 0\n",
    "similarity_rate = 0\n",
    "similarity_rate_hap = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):   # 5개의 기존 청원글\n",
    "    for k in range(5): # 5개의 상위토큰           \n",
    "        similarity_rate = ko_model.wv.similarity(new_final_token[k], sorted_petition.iloc[i].iloc[2][k]) # 1:1 유사도\n",
    "#         print(similarity_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <유사도 기반 청원수 예측>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = 0\n",
    "denominator = 0\n",
    "\n",
    "for i in range(5):   # 5개의 기존 청원글\n",
    "    for k in range(5): # 5개의 상위토큰           \n",
    "        similarity_rate = ko_model.wv.similarity(new_final_token[k], sorted_petition.iloc[i].iloc[2][k]) # 1:1 유사도\n",
    "        similarity_rate_hap += similarity_rate\n",
    "    similarity_rate_mean = similarity_rate_hap / 5   # 상위토큰 5개의 유사도 평균\n",
    "    \n",
    "    weighted_petition_number = similarity_rate_mean * sorted_petition.iloc[i].iloc[1] # 유사도*청원수\n",
    "    numerator += weighted_petition_number  # 분자(유사도*청원수 총합)\n",
    "    denominator += similarity_rate  # 분모(유사도 총합) \n",
    "    \n",
    "final_prediction = numerator/denominator\n",
    "print(\"예상 청원수: \", final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
